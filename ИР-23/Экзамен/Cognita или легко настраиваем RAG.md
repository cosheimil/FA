# План статьи
1. Приветствие
2. Зачем нужен RAG
3. Cognita. Что умеет, плюсы/минусы
4. Настраиваемся на работу. Основные компоненты Cognita
5. Примерчики
6. Заключение

Привет, чемпионы! 2 года назад RAG было чем-то непонятным и сложным, чтобы настроить его надо было нанимать целую команду инеженеров. А сегодня RAG можно настроить, написав адаптер для модели и указать путь к вашим документам - и все. Генерация с дополненной выборкой скоро станет таким же базовым навыком, как и линейная регрессия - так что погружаемся глубже и разбираемся в новом фреймворке Cognita

# Зачем нужен RAG
Но сперва уточним, когда стоит применять RAG, а когда стоит подольше подумать над промптом для LLM. RAG (Retrieval Augmented Generation) - метод для работы с языковыми моделями, когда модель получает запрос от пользователя, а мы программно подсказываем модели, где она может найти гипотетический ответ на вопрос. Например:

- Пользователь: Сколько сейчас открыто Dodo пиццерий?
- Модель не училась на данных сегодняшнего дня, поэтому она точно не может знать ответ. Эту информацию она должна получить откуда-то
- Чтобы ответить на этот вопрос нейронок обучать не надо - идем в интернет и спрашиваем у Google сколько точек открыто. Собираем все возможные ответы и скармливаем модели
- После этого она выбирает нужный ответ и пользователь доволен
![[Pasted image 20240718190353.png]]
Кажется это офигенная техника, бежим внедряем во все проекты и радуемся. Не все так просто
Если у вас:
- Данные - таблицы
- Важна скорость генерации
- Документы не содержат как такого ответа
- Важно качество ответа в едином стиле
То подумайте несколько раз, чтобы применять такую генерацию. Мы же подумали миллион раз, так что разбираемся с библиотекой

# Cognita
>Cognita — это универсальная среда RAG с открытым исходным кодом, предназначенная для того, чтобы лидеры в области обработки данных, машинного обучения и разработки платформ могли быстро создавать и развертывать масштабируемые приложения RAG. Он имеет полностью модульную, удобную и адаптируемую архитектуру, обеспечивающую полную безопасность и соответствие требованиям.
\- Информация с сайта разработчиков

[Cognita](https://www.truefoundry.com/cognita) разработана ребятами из truefoundry, цель которых создавать быстрые и безопасные ML, LLM решения. Основные фишки:
- Полностью модульное решение
- Готов работать на нескольких машинах при развертывании
- Используемость конфигов

## Модульность
Наверное самый жирный плюс данного проекта, в чем же он заключается? Допустим вам понадобилось написать особенный модуль для поиска по базе данных. Вы абсолютные чемпионы и справились с этой задачей на ура, а вот ваш RAG-фреймворк не поддерживает этой фичи по дефолту. Поэтому вам приходится лесть в исходный код и добавлять это все ручками. И это в 2024 году!

Cognita исправляет этот недостаток. Написав свой код, вы прикручиваете к нему API из документации, а потом добавляете ваш адаптер. Вы прекрасны

## Скорость
Чтобы развернуть RAG вам больше не надо писать свой k8s или docker-compose, так как сегодняшний герой уже "из коробки" использует последний тип оркестрации

![[Pasted image 20240718185605.png]]
Также вам не надо задумываться над главными проблема при интеграции в свой проект:
- Как распарсить pdf-ки
- Данные находятся в китайском облаке
- Поиск по данным
- Распределение нагрузки

Основные же минусы:
- Разбиение на чанки и подсчет эмбеддингов придется настроить самому, чтобы работало распределнно
- Векторные базы данных на данный момент сложно внедрить
- Чтобы развернуть свою LLM необходимо написать адаптер

Минусы связаны с возрастом проекта - 3 месяца. За этот период смогли решить множество проблем, но также осталось много работы. Так что верим в разработчиков и ждем новых релизов. А мы переходим плавно к тестам!

# Примеры
Чтобы попробовать Cognita даже не нужно запускать его на серверах, можно попробовать и дома через [Cognita UI](https://cognita.truefoundry.com/). Перейдя на сайт видим неплохой интерфейс:
![[Pasted image 20240718191109.png]]
Слева мы можем базово настроить RAG, выбрав:
- Контроллер
- Базу знаний
- Модель для генерации
- Гиперпараметры LLM
- Тип поиска
- И его параметры
- Шаблон промпта

Давайте зададим какой-то профильный вопрос, на который базовая LLM не способна ответить, например: `What is antibiotic?` 

Получаем ответ: <...>

В тоже самое время ChatGPT выдает нам ответ: <...>

Также если вы хотите получить проект с chat интерфейсом, то можете нажать на кнопку `Create Application` и получите диалоговое окно, где можете чатиться с настроенной моделью
![[Pasted image 20240718192526.png]]

# Заключение
Настройка RAG стала в миллион раз легче, чем пару лет назад. С каждым днем появляется все больше и больше открытых и бесплатных проектов, которые вы можете применять каждый день в своей работе. Так что может быть RAG и вовсе скоро будет реализован также, как линейная регрессия из sklearn. Где вам можно сделать импорт и все методы реализованы. Тратьте время только на воплощение своих идей, а не на сервисный deploy. Stay tuned, чемпионы!