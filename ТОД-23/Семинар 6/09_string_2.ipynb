{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymorphy2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymorphy2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymorphy2'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy for them  yogurt popsicles</td>\n",
       "      <td>my children and their friends ask for my homem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i can t believe it s spinach</td>\n",
       "      <td>these were so go it surprised even me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>italian  gut busters</td>\n",
       "      <td>my sisterinlaw made these for us at a family g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love is in the air  beef fondue   sauces</td>\n",
       "      <td>i think a fondue is a very romantic casual din...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name  \\\n",
       "0     george s at the cove  black bean soup   \n",
       "1        healthy for them  yogurt popsicles   \n",
       "2              i can t believe it s spinach   \n",
       "3                      italian  gut busters   \n",
       "4  love is in the air  beef fondue   sauces   \n",
       "\n",
       "                           preprocessed_descriptions  \n",
       "0  an original recipe created by chef scott meska...  \n",
       "1  my children and their friends ask for my homem...  \n",
       "2              these were so go it surprised even me  \n",
       "3  my sisterinlaw made these for us at a family g...  \n",
       "4  i think a fondue is a very romantic casual din...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('preprocessed_descriptions.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.preprocessed_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aaaahhhhhamazing', 'aaaahing', ..., 'zwtii', 'zwtlaos',\n",
       "       'zzar'], dtype='<U100')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = list()\n",
    "\n",
    "for text in data:\n",
    "    try:\n",
    "        n += [x for x in nltk.word_tokenize(text) if x.isalpha()]\n",
    "    except TypeError as e:\n",
    "        pass\n",
    "    \n",
    "arr = np.array(n)\n",
    "\n",
    "arr = np.unique(arr)\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(arr, size=(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance between 'coconut' and 'fireplace' is 14\n",
      "Edit distance between 'originated' and 'grenada' is 9\n",
      "Edit distance between 'preservative' and 'slim' is 12\n",
      "Edit distance between 'deficient' and 'redorange' is 14\n",
      "Edit distance between 'vibrant' and 'marino' is 9\n"
     ]
    }
   ],
   "source": [
    "for s1, s2 in sample:\n",
    "    print(f\"Edit distance between '{s1}' and '{s2}' is {edit_distance(s1, s2, substitution_cost=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest(word, k, words):\n",
    "    sorted_words = sorted(words, key=lambda x: edit_distance(word, x))\n",
    "    return sorted_words[1:k+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accompany'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_word = np.random.choice(arr)\n",
    "random_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company', 'accompanied', 'accompanies', 'accompaning', 'accompanying', 'companys', 'accomadate', 'accomodate', 'accompanyment', 'accomplish']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest(random_word, 10, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stems = list()\n",
    "lems = list()\n",
    "\n",
    "for word in arr:\n",
    "    stems.append(stemmer.stem(word))\n",
    "    lems.append(lemmatizer.lemmatize(word))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahhhhhamazing</th>\n",
       "      <td>aaaahhhhhamaz</td>\n",
       "      <td>aaaahhhhhamazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahing</th>\n",
       "      <td>aaaah</td>\n",
       "      <td>aaaahing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaahs</th>\n",
       "      <td>aaah</td>\n",
       "      <td>aaahs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaar</th>\n",
       "      <td>aaar</td>\n",
       "      <td>aaar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwarte</th>\n",
       "      <td>zwart</td>\n",
       "      <td>zwarte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwt</th>\n",
       "      <td>zwt</td>\n",
       "      <td>zwt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwtii</th>\n",
       "      <td>zwtii</td>\n",
       "      <td>zwtii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwtlaos</th>\n",
       "      <td>zwtlao</td>\n",
       "      <td>zwtlaos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzar</th>\n",
       "      <td>zzar</td>\n",
       "      <td>zzar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30743 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stemmed_word   normalized_word\n",
       "a                             a                 a\n",
       "aaaahhhhhamazing  aaaahhhhhamaz  aaaahhhhhamazing\n",
       "aaaahing                  aaaah          aaaahing\n",
       "aaahs                      aaah             aaahs\n",
       "aaar                       aaar              aaar\n",
       "...                         ...               ...\n",
       "zwarte                    zwart            zwarte\n",
       "zwt                         zwt               zwt\n",
       "zwtii                     zwtii             zwtii\n",
       "zwtlaos                  zwtlao           zwtlaos\n",
       "zzar                       zzar              zzar\n",
       "\n",
       "[30743 rows x 2 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(stems,index=arr)\n",
    "df = pd.DataFrame(data=ser, columns=['stemmed_word'])\n",
    "df['normalized_word'] = lems\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = list()\n",
    "\n",
    "for text in data:\n",
    "    try:\n",
    "        n += [x for x in nltk.word_tokenize(text) if x.isalpha()]\n",
    "    except TypeError as e:\n",
    "        pass\n",
    "    \n",
    "arr = np.array(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist = FreqDist(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 40072), ('a', 34951), ('and', 30245), ('this', 26859), ('i', 24836), ('to', 23471), ('is', 20285), ('it', 19756), ('of', 18364), ('for', 15939)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_arr = [x for x in arr if x not in eng_stop]\n",
    "\n",
    "sdist = FreqDist(cleared_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recipe', 14871), ('make', 6326), ('time', 5137), ('use', 4620), ('great', 4430), ('like', 4167), ('easy', 4152), ('one', 3872), ('made', 3810), ('good', 3791)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5386528718649717"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleared_arr) / len(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>preprocessed_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27933</th>\n",
       "      <td>totally tropical genuine rum punch</td>\n",
       "      <td>just inflate a plastic palm tree blow up a pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>broccolini  ricotta pasta</td>\n",
       "      <td>i just saw this pasta being made on rachel ray...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>fresh mint ice cream</td>\n",
       "      <td>there are no words that can describe fresh hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23768</th>\n",
       "      <td>seafood spaghetti</td>\n",
       "      <td>heres a delicious spaghetti recipe this is a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20985</th>\n",
       "      <td>platanos maduros  costa rican fried ripe plant...</td>\n",
       "      <td>i learned to make these from my friend adrin m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "27933                 totally tropical genuine rum punch   \n",
       "3864                           broccolini  ricotta pasta   \n",
       "11389                               fresh mint ice cream   \n",
       "23768                                  seafood spaghetti   \n",
       "20985  platanos maduros  costa rican fried ripe plant...   \n",
       "\n",
       "                               preprocessed_descriptions  \n",
       "27933  just inflate a plastic palm tree blow up a pla...  \n",
       "3864   i just saw this pasta being made on rachel ray...  \n",
       "11389  there are no words that can describe fresh hom...  \n",
       "23768  heres a delicious spaghetti recipe this is a w...  \n",
       "20985  i learned to make these from my friend adrin m...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_csv('preprocessed_descriptions.csv').sample(5)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27933    just inflate a plastic palm tree blow up a pla...\n",
       "3864     i just saw this pasta being made on rachel ray...\n",
       "11389    there are no words that can describe fresh hom...\n",
       "23768    heres a delicious spaghetti recipe this is a w...\n",
       "20985    i learned to make these from my friend adrin m...\n",
       "Name: preprocessed_descriptions, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df_sample.preprocessed_descriptions\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer()\n",
    "\n",
    "corpus_tv = tv.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30', 'adrin', 'almost', 'although', 'and', 'approximate', 'are',\n",
       "       'as', 'bananas', 'be', 'beans', 'being', 'black', 'blow', 'bread',\n",
       "       'brush', 'but', 'by', 'can', 'close', 'college', 'cooking',\n",
       "       'costa', 'cream', 'crusty', 'dancing', 'decided', 'delicious',\n",
       "       'describe', 'dessertlikeyou', 'different', 'dish', 'do', 'easy',\n",
       "       'eaten', 'enough', 'eyes', 'fast', 'favorite', 'find', 'fish',\n",
       "       'fixes', 'for', 'frequently', 'fresh', 'freshest', 'friend',\n",
       "       'from', 'gallo', 'garlic', 'gave', 'go', 'goand', 'got', 'great',\n",
       "       'hammock', 'hang', 'have', 'he', 'heres', 'hes', 'him', 'his',\n",
       "       'homemade', 'hope', 'household', 'ice', 'imagine', 'in', 'include',\n",
       "       'inflate', 'instructions', 'is', 'it', 'its', 'just', 'keeping',\n",
       "       'kitchen', 'learned', 'like', 'limbo', 'local', 'look', 'love',\n",
       "       'low', 'made', 'make', 'marchena', 'may', 'me', 'meal', 'meals',\n",
       "       'meat', 'mint', 'minute', 'monger', 'monkey', 'more', 'most', 'my',\n",
       "       'next', 'no', 'not', 'of', 'on', 'or', 'own', 'palm', 'pasta',\n",
       "       'personally', 'pinto', 'plantains', 'plastic', 'post', 'produce',\n",
       "       'product', 'punch', 'puntarenas', 'put', 'quite', 'rachel', 'rays',\n",
       "       'really', 'recipe', 'rica', 'ricans', 'rice', 'rum', 'safe', 'saw',\n",
       "       'seafood', 'section', 'seems', 'semester', 'showcased', 'side',\n",
       "       'sip', 'skillshow', 'snap', 'so', 'some', 'spaghetti', 'spent',\n",
       "       'stepbystep', 'stood', 'supermarkets', 'sure', 'sweet', 'that',\n",
       "       'the', 'there', 'theretotally', 'these', 'they', 'think', 'this',\n",
       "       'ticos', 'times', 'to', 'togetherthis', 'tree', 'tropical', 'try',\n",
       "       'types', 'up', 'vary', 'vegetablethey', 'was', 'way', 'well',\n",
       "       'while', 'will', 'with', 'wonderful', 'words', 'would', 'you',\n",
       "       'your', 'yours'], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.08850685,\n",
       "        0.        , 0.08850685, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.15709903, 0.        ,\n",
       "        0.15709903, 0.        , 0.        , 0.08850685, 0.15709903,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15709903, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15709903, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15709903, 0.        , 0.        ,\n",
       "        0.15709903, 0.15709903, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15709903, 0.        , 0.        ,\n",
       "        0.15709903, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10521105, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15709903, 0.        , 0.        , 0.        , 0.15709903,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15709903, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.25349302,\n",
       "        0.        , 0.        , 0.15709903, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31419806, 0.        , 0.        ,\n",
       "        0.        , 0.15709903, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15709903, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15709903, 0.15709903, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15709903, 0.        , 0.        , 0.        ,\n",
       "        0.10521105, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15709903, 0.15709903, 0.        , 0.        , 0.38023953,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25349302, 0.25349302, 0.        ],\n",
       "       [0.14655473, 0.        , 0.        , 0.14655473, 0.16513276,\n",
       "        0.        , 0.        , 0.09814941, 0.        , 0.        ,\n",
       "        0.        , 0.14655473, 0.        , 0.        , 0.14655473,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14655473,\n",
       "        0.        , 0.14655473, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.14655473, 0.        , 0.14655473, 0.        ,\n",
       "        0.14655473, 0.        , 0.14655473, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11823943, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14655473,\n",
       "        0.        , 0.14655473, 0.        , 0.        , 0.14655473,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23647887, 0.11823943,\n",
       "        0.09814941, 0.14655473, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11823943, 0.11823943, 0.        , 0.        , 0.        ,\n",
       "        0.14655473, 0.        , 0.        , 0.        , 0.14655473,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23647887,\n",
       "        0.        , 0.14655473, 0.        , 0.11823943, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.14655473, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14655473, 0.14655473, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.14655473, 0.14655473,\n",
       "        0.        , 0.        , 0.14655473, 0.        , 0.14655473,\n",
       "        0.14655473, 0.        , 0.        , 0.        , 0.14655473,\n",
       "        0.11823943, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14655473,\n",
       "        0.29444823, 0.        , 0.        , 0.19629882, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14655473, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09814941, 0.        , 0.        ,\n",
       "        0.14655473, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.17741967, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.17741967, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31491864, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31491864, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.31491864,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31491864, 0.        ,\n",
       "        0.        , 0.31491864, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31491864, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31491864, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21090468, 0.        ,\n",
       "        0.31491864, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.31491864,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.06099792,\n",
       "        0.10827088, 0.06099792, 0.07251027, 0.        , 0.21654175,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08735226, 0.        , 0.06099792, 0.        ,\n",
       "        0.        , 0.10827088, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10827088, 0.        , 0.        ,\n",
       "        0.21654175, 0.        , 0.10827088, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10827088, 0.        ,\n",
       "        0.32481263, 0.10827088, 0.08735226, 0.        , 0.        ,\n",
       "        0.10827088, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10827088, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.10827088,\n",
       "        0.10827088, 0.        , 0.        , 0.        , 0.10827088,\n",
       "        0.10827088, 0.        , 0.        , 0.17470452, 0.08735226,\n",
       "        0.        , 0.        , 0.21654175, 0.08735226, 0.08735226,\n",
       "        0.07251027, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10827088, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10827088, 0.        , 0.        , 0.        , 0.08735226,\n",
       "        0.        , 0.        , 0.08735226, 0.17470452, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08735226, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21654175, 0.        ,\n",
       "        0.        , 0.        , 0.10827088, 0.21654175, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10827088, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.10827088, 0.        ,\n",
       "        0.        , 0.10827088, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10827088, 0.        , 0.07251027, 0.08735226,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.14502054, 0.        , 0.21654175, 0.14502054, 0.10827088,\n",
       "        0.        , 0.        , 0.10827088, 0.21654175, 0.08735226,\n",
       "        0.10827088, 0.        , 0.        , 0.10827088, 0.10827088,\n",
       "        0.        , 0.10827088, 0.07251027, 0.10827088, 0.        ,\n",
       "        0.        , 0.17470452, 0.08735226, 0.10827088],\n",
       "       [0.        , 0.09686831, 0.09686831, 0.        , 0.21829566,\n",
       "        0.        , 0.16372175, 0.06487384, 0.09686831, 0.        ,\n",
       "        0.09686831, 0.        , 0.09686831, 0.        , 0.        ,\n",
       "        0.        , 0.15630548, 0.09686831, 0.05457392, 0.        ,\n",
       "        0.09686831, 0.        , 0.19373662, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09686831,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09686831,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09686831,\n",
       "        0.        , 0.        , 0.        , 0.09686831, 0.        ,\n",
       "        0.        , 0.09686831, 0.09686831, 0.09686831, 0.        ,\n",
       "        0.09686831, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09686831, 0.09686831, 0.        ,\n",
       "        0.        , 0.09686831, 0.09686831, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31261097, 0.07815274,\n",
       "        0.        , 0.09686831, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09686831, 0.09686831, 0.09686831,\n",
       "        0.        , 0.09686831, 0.09686831, 0.09686831, 0.        ,\n",
       "        0.07815274, 0.07815274, 0.09686831, 0.        , 0.09686831,\n",
       "        0.        , 0.09686831, 0.09686831, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09686831, 0.09686831, 0.07815274,\n",
       "        0.09686831, 0.        , 0.07815274, 0.15630548, 0.        ,\n",
       "        0.09686831, 0.        , 0.        , 0.        , 0.09686831,\n",
       "        0.09686831, 0.09686831, 0.        , 0.        , 0.09686831,\n",
       "        0.09686831, 0.        , 0.09686831, 0.        , 0.09686831,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09686831,\n",
       "        0.09686831, 0.09686831, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09686831, 0.        , 0.09686831, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.07815274, 0.        , 0.09686831, 0.09686831, 0.09686831,\n",
       "        0.09686831, 0.        , 0.09686831, 0.06487384, 0.07815274,\n",
       "        0.        , 0.        , 0.38747324, 0.09686831, 0.        ,\n",
       "        0.        , 0.09686831, 0.        , 0.12974767, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09686831, 0.        , 0.        , 0.        ,\n",
       "        0.09686831, 0.        , 0.06487384, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = corpus_tv.toarray()\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pairwise_similarity = corpus_tv * corpus_tv.T\n",
    "pairwise_similarity.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = [[0 for _ in range(5)] for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vectors)):\n",
    "    for j in range(len(vectors)):  \n",
    "        correlation[i][j] = scipy.spatial.distance.cosine(vectors[i], vectors[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(data=correlation, index=df_sample.name, columns=df_sample.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>totally tropical genuine rum punch</th>\n",
       "      <th>broccolini  ricotta pasta</th>\n",
       "      <th>fresh mint ice cream</th>\n",
       "      <th>seafood spaghetti</th>\n",
       "      <th>platanos maduros  costa rican fried ripe plantains</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>totally tropical genuine rum punch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884133</td>\n",
       "      <td>0.968594</td>\n",
       "      <td>0.861273</td>\n",
       "      <td>0.961359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broccolini  ricotta pasta</th>\n",
       "      <td>0.884133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.898026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresh mint ice cream</th>\n",
       "      <td>0.968594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963063</td>\n",
       "      <td>0.947588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seafood spaghetti</th>\n",
       "      <td>0.861273</td>\n",
       "      <td>0.845766</td>\n",
       "      <td>0.963063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platanos maduros  costa rican fried ripe plantains</th>\n",
       "      <td>0.961359</td>\n",
       "      <td>0.898026</td>\n",
       "      <td>0.947588</td>\n",
       "      <td>0.817558</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                                                totally tropical genuine rum punch  \\\n",
       "name                                                                                     \n",
       "totally tropical genuine rum punch                                            0.000000   \n",
       "broccolini  ricotta pasta                                                     0.884133   \n",
       "fresh mint ice cream                                                          0.968594   \n",
       "seafood spaghetti                                                             0.861273   \n",
       "platanos maduros  costa rican fried ripe plantains                            0.961359   \n",
       "\n",
       "name                                                broccolini  ricotta pasta  \\\n",
       "name                                                                            \n",
       "totally tropical genuine rum punch                                   0.884133   \n",
       "broccolini  ricotta pasta                                            0.000000   \n",
       "fresh mint ice cream                                                 1.000000   \n",
       "seafood spaghetti                                                    0.845766   \n",
       "platanos maduros  costa rican fried ripe plantains                   0.898026   \n",
       "\n",
       "name                                                fresh mint ice cream  \\\n",
       "name                                                                       \n",
       "totally tropical genuine rum punch                              0.968594   \n",
       "broccolini  ricotta pasta                                       1.000000   \n",
       "fresh mint ice cream                                            0.000000   \n",
       "seafood spaghetti                                               0.963063   \n",
       "platanos maduros  costa rican fried ripe plantains              0.947588   \n",
       "\n",
       "name                                                seafood spaghetti  \\\n",
       "name                                                                    \n",
       "totally tropical genuine rum punch                           0.861273   \n",
       "broccolini  ricotta pasta                                    0.845766   \n",
       "fresh mint ice cream                                         0.963063   \n",
       "seafood spaghetti                                            0.000000   \n",
       "platanos maduros  costa rican fried ripe plantains           0.817558   \n",
       "\n",
       "name                                                platanos maduros  costa rican fried ripe plantains  \n",
       "name                                                                                                    \n",
       "totally tropical genuine rum punch                                                           0.961359   \n",
       "broccolini  ricotta pasta                                                                    0.898026   \n",
       "fresh mint ice cream                                                                         0.947588   \n",
       "seafood spaghetti                                                                            0.817558   \n",
       "platanos maduros  costa rican fried ripe plantains                                           0.000000   "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наиболее похожими являются те рецепты, у которых косинусное расстояние наименьшое (стремится к нулю).\n",
    "### На данной выборке минимальное косинусное расстояние у рецептов платанос мадурос) и сифуд спагети"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
